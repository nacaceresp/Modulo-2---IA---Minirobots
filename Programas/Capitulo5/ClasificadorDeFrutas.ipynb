{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Tome un conjunto de manzanas, un conjunto de peras, un conjunto de bananos y\n",
    "un conjunto de fresas. Desarrolle un sistema clasificador de estas cuatro frutas, de\n",
    "manera que después de entrenar la red se le den imágenes de frutas de internet y\n",
    "el sistema las clasifique. Obténgalos de: https://www.kaggle.com/moltean/fruits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] El sistema no puede encontrar la ruta especificada: 'frutas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m datagen \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mpreprocessing\u001b[39m.\u001b[39mimage\u001b[39m.\u001b[39mImageDataGenerator(rescale\u001b[39m=\u001b[39m\u001b[39m1.\u001b[39m\u001b[39m/\u001b[39m\u001b[39m255\u001b[39m, validation_split\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[39m# Cargar las imágenes de entrenamiento y validación\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m train_data \u001b[39m=\u001b[39m datagen\u001b[39m.\u001b[39;49mflow_from_directory(\n\u001b[0;32m     17\u001b[0m     directory\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mfrutas\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m     18\u001b[0m     target_size\u001b[39m=\u001b[39;49mimage_size,\n\u001b[0;32m     19\u001b[0m     subset\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtraining\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[0;32m     20\u001b[0m )\n\u001b[0;32m     22\u001b[0m validation_data \u001b[39m=\u001b[39m datagen\u001b[39m.\u001b[39mflow_from_directory(\n\u001b[0;32m     23\u001b[0m     directory\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfrutas\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     24\u001b[0m     target_size\u001b[39m=\u001b[39mimage_size,\n\u001b[0;32m     25\u001b[0m     subset\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mvalidation\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     26\u001b[0m )\n\u001b[0;32m     28\u001b[0m \u001b[39m# Paso 3: Crear el modelo de clasificación\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[39m# Utilizaremos una arquitectura simple de CNN\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\keras\\preprocessing\\image.py:1648\u001b[0m, in \u001b[0;36mImageDataGenerator.flow_from_directory\u001b[1;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[0;32m   1562\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflow_from_directory\u001b[39m(\n\u001b[0;32m   1563\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   1564\u001b[0m     directory,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1578\u001b[0m     keep_aspect_ratio\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m   1579\u001b[0m ):\n\u001b[0;32m   1580\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Takes the path to a directory & generates batches of augmented data.\u001b[39;00m\n\u001b[0;32m   1581\u001b[0m \n\u001b[0;32m   1582\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1646\u001b[0m \u001b[39m            and `y` is a numpy array of corresponding labels.\u001b[39;00m\n\u001b[0;32m   1647\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1648\u001b[0m     \u001b[39mreturn\u001b[39;00m DirectoryIterator(\n\u001b[0;32m   1649\u001b[0m         directory,\n\u001b[0;32m   1650\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1651\u001b[0m         target_size\u001b[39m=\u001b[39;49mtarget_size,\n\u001b[0;32m   1652\u001b[0m         color_mode\u001b[39m=\u001b[39;49mcolor_mode,\n\u001b[0;32m   1653\u001b[0m         keep_aspect_ratio\u001b[39m=\u001b[39;49mkeep_aspect_ratio,\n\u001b[0;32m   1654\u001b[0m         classes\u001b[39m=\u001b[39;49mclasses,\n\u001b[0;32m   1655\u001b[0m         class_mode\u001b[39m=\u001b[39;49mclass_mode,\n\u001b[0;32m   1656\u001b[0m         data_format\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata_format,\n\u001b[0;32m   1657\u001b[0m         batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m   1658\u001b[0m         shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[0;32m   1659\u001b[0m         seed\u001b[39m=\u001b[39;49mseed,\n\u001b[0;32m   1660\u001b[0m         save_to_dir\u001b[39m=\u001b[39;49msave_to_dir,\n\u001b[0;32m   1661\u001b[0m         save_prefix\u001b[39m=\u001b[39;49msave_prefix,\n\u001b[0;32m   1662\u001b[0m         save_format\u001b[39m=\u001b[39;49msave_format,\n\u001b[0;32m   1663\u001b[0m         follow_links\u001b[39m=\u001b[39;49mfollow_links,\n\u001b[0;32m   1664\u001b[0m         subset\u001b[39m=\u001b[39;49msubset,\n\u001b[0;32m   1665\u001b[0m         interpolation\u001b[39m=\u001b[39;49minterpolation,\n\u001b[0;32m   1666\u001b[0m         dtype\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtype,\n\u001b[0;32m   1667\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\keras\\preprocessing\\image.py:563\u001b[0m, in \u001b[0;36mDirectoryIterator.__init__\u001b[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m classes:\n\u001b[0;32m    562\u001b[0m     classes \u001b[39m=\u001b[39m []\n\u001b[1;32m--> 563\u001b[0m     \u001b[39mfor\u001b[39;00m subdir \u001b[39min\u001b[39;00m \u001b[39msorted\u001b[39m(os\u001b[39m.\u001b[39;49mlistdir(directory)):\n\u001b[0;32m    564\u001b[0m         \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(directory, subdir)):\n\u001b[0;32m    565\u001b[0m             classes\u001b[39m.\u001b[39mappend(subdir)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] El sistema no puede encontrar la ruta especificada: 'frutas'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Paso 1: Cargar y preparar los datos\n",
    "# Supongamos que tienes un directorio llamado \"frutas\" que contiene subdirectorios separados para cada tipo de fruta.\n",
    "# Asegúrate de tener imágenes etiquetadas de manzanas, peras, bananos y fresas en sus respectivos subdirectorios.\n",
    "\n",
    "# Paso 2: Preprocesamiento de las imágenes\n",
    "# Define el tamaño de las imágenes\n",
    "image_size = (64, 64)\n",
    "# Utiliza ImageDataGenerator para cargar y preprocesar las imágenes\n",
    "datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "# Cargar las imágenes de entrenamiento y validación\n",
    "train_data = datagen.flow_from_directory(\n",
    "    directory='frutas',\n",
    "    target_size=image_size,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_data = datagen.flow_from_directory(\n",
    "    directory='frutas',\n",
    "    target_size=image_size,\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Paso 3: Crear el modelo de clasificación\n",
    "# Utilizaremos una arquitectura simple de CNN\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(image_size[0], image_size[1], 3)),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(4, activation='softmax')  # 4 clases de frutas: manzanas, peras, bananos, fresas\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Paso 4: Entrenar el modelo\n",
    "epochs = 10\n",
    "model.fit(train_data, epochs=epochs, validation_data=validation_data)\n",
    "\n",
    "# Paso 5: Evaluar el modelo\n",
    "test_loss, test_acc = model.evaluate(validation_data)\n",
    "print('Precisión en el conjunto de prueba:', test_acc)\n",
    "\n",
    "# Paso 6: Clasificar nuevas imágenes\n",
    "# Carga una nueva imagen para clasificar\n",
    "new_image = keras.preprocessing.image.load_img('nueva_fruta.jpg', target_size=image_size)\n",
    "new_image = keras.preprocessing.image.img_to_array(new_image)\n",
    "new_image = tf.expand_dims(new_image, 0)  # Agrega una dimensión adicional para que coincida con el tamaño de entrada del modelo\n",
    "\n",
    "# Realiza la clasificación de la nueva imagen\n",
    "predictions = model.predict(new_image)\n",
    "class_index = tf.argmax(predictions[0])\n",
    "class_labels = train_data.class_indices\n",
    "\n",
    "# Imprime la etiqueta de fruta correspondiente a la clasificación\n",
    "for label, index in class_labels.items():\n",
    "    if index == class_index:\n",
    "        print('La fruta es:', label)\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
